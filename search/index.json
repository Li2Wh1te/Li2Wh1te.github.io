[{"content":"数组 概述 数组是由相同类型元素的集合组成的数据结构，计算机会为数组分配一块连续的内存保存其中的元素，可以通过数组中元素的索引快速访问特定元素。数组作为基本的数据类型，通常用两个维度描述：数组中存储的元素类型和数组长度，数组在初始化之后大小无法改变。\n初始化 数组的初始化分为两种：一种是显式的指定数组大小，另一种是使用 [...] T声明数组，Go 语言会在编译期间通过源代码推导数组的大小。\n1 2  arr1 := [3]int{1, 2, 3} arr2 := [...]int{1, 2, 3}   以上两种方式得到的结果是相同的，后一种声明方式在编译期间会被转换成前一种，也就是编译器对数组大小的推导。\n对于一个由字面量组成的数组，根据数组元素数量的不同，编译器会在负责初始化字面量的 cmd/compile/internal/gc.anylit 函数中做两种不同的优化。在不考虑逃逸分析的前提下：\n 当元素数量小于或者等于 4 个时，会直接将数组中的元素放置在栈上 当元素数量大于 4 个时，会将数组中的元素放置到静态区并在运行时取出  切片（Slice） 数据结构 一个slice由三部分组成：指针、长度、容量。\n1 2 3 4 5 6  // runtime/slice.go type slice struct { array unsafe.Pointer // 元素指针 \tlen int // 长度 \tcap int // 容量 }   指针指向第一个slice元素对应的底层数组元素的地址，要注意的是slice的第一个元素并不一定就是数组的第一个元素。长度对应slice中元素的数目；长度不能超过容量，容量一般是从slice的开始位置到底层数据的结尾位置。\n初始化 Go语言包含三种初始化slice的方式：\n 通过下标的方式获得数组或是切片的一部分 使用字面量初始化新的切片 使用关键字make创建切片  1 2 3  arr[0:3] or slice[0:3] slice := []int{1, 2, 3} slice := make([]int, 10)   追加和扩容 使用append可以向slice追加元素，实际上是往底层数组添加元素。不过因为底层数组的容量固定的，所以在容量不足时，会触发slice的扩容。\n在1.18版本更新之后，slice的扩容策略变为了：\n 如果期望容量大于slice原容量的两倍就会直接使用期望容量 当slice原容量x小于256时，新容量y为原来的两倍 当slice原容量x大于等于256时，新容量y = x + (x + 3*256) / 4  以上只是确定切片的大致容量，下面还需要根据切片中的元素大小进行内存对齐。runtime.roundupsize 函数会将待申请的内存向上取整，取整时会使用 runtime.class_to_size 数组，使用该数组中的整数可以提高内存的分配效率并减少碎片。\n哈希表 哈希表是计算机科学中的最重要数据结构之一，这不仅因为它 𝑂(1) 的读写性能非常优秀，还因为它提供了键值之间的映射。想要实现一个性能优异的哈希表，需要注意两个关键点 —— 哈希函数和冲突解决方法。\n设计原理 哈希函数 实现哈希表的关键点在于哈希函数的选择，哈希函数的选择在很大程度上能够决定哈希表的读写性能。在理想情况下，哈希函数应该能够将不同键映射到不同的索引上，这要求哈希函数的输出范围大于输入范围，但是由于键的数量会远远大于映射的范围，所以在实际使用时，这个理想的效果是不可能实现的。\n如果使用结果分布较为均匀的哈希函数，那么哈希的增删改查的时间复杂度为 𝑂(1) ；但是如果哈希函数的结果分布不均匀，那么所有操作的时间复杂度可能会达到 𝑂(𝑛) ，由此看来，使用好的哈希函数是至关重要的。\n冲突解决 在通常情况下，哈希函数输入的范围一定会远远大于输出的范围，所以在使用哈希表时一定会遇到冲突，哪怕我们使用了完美的哈希函数，当输入的键足够多也会产生冲突。然而多数的哈希函数都是不够完美的，所以仍然存在发生哈希碰撞的可能，这时就需要一些方法来解决哈希碰撞的问题，常见方法的就是开放寻址法和拉链法。\n开放寻址法 开放寻址法是一种在哈希表中解决哈希碰撞的方法，这种方法的核心思想是依次探测和比较数组中的元素以判断目标键值对是否存在于哈希表中。\n开放寻址法中对性能影响最大的是装载因子，它是数组中元素的数量与数组大小的比值。随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会影响哈希表的读写性能。当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找和插入任意元素的时间复杂度都是 𝑂(𝑛) 的，这时需要遍历数组中的全部元素，所以在实现哈希表时一定要关注装载因子的变化。\n拉链法 拉链法会使用链表数组作为哈希底层的数据结构，我们可以将它看成可以扩展的二维数组。\n与开放地址法一样，拉链法的装载因子（装载因子 = 元素数量 / 桶数量 ）越大，哈希的读写性能就越差。在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍。\n数据结构 runtime同时使用了多个数据结构组合表示哈希表，其中runtime.hmap是最核心的结构体，字段如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/reflectdata/reflect.go. \t// Make sure this stays in sync with the compiler\u0026#39;s definition. \tcount int // # live cells == size of map. Must be first (used by len() builtin) \tflags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) \tnoverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details \thash0 uint32 // hash seed  buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. \toldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing \tnevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated)  extra *mapextra // optional fields }    count表示当前哈希表中的元素数量 B表示当前哈希表持有的 buckets 数量，但是因为哈希表中桶的数量都 2 的倍数，所以该字段会存储对数，也就是 len(buckets) == 2^B hash0是哈希的种子，它能为哈希函数的结果引入随机性，这个值在创建哈希表时确定，并在调用哈希函数时作为参数传入 oldbuckets是哈希在扩容时用于保存之前 buckets 的字段，它的大小是当前 buckets 的一半  如上图所示哈希表 runtime.hmap 的桶是 runtime.bmap。每一个 runtime.bmap 都能存储 8 个键值对，当哈希表中存储的数据过多，单个桶已经装满时就会使用 extra.nextOverflow 中桶存储溢出的数据。上述两种不同的桶在内存中是连续存储的，我们在这里将它们分别称为正常桶和溢出桶，上图中黄色的 runtime.bmap 就是正常桶，绿色的 runtime.bmap 是溢出桶。\n桶的结构体 runtime.bmap 在 Go 语言源代码中的定义只包含一个简单的 tophash 字段，tophash 存储了键的哈希的高 8 位，通过比较不同键的哈希的高 8 位可以减少访问键值对次数以提高性能：\n1 2 3  type bmap struct { tophash [bucketCnt]uint8 }   在运行期间，runtime.bmap 结构体其实不止包含 tophash 字段，因为哈希表中可能存储不同类型的键值对，而且 Go 语言也不支持泛型，所以键值对占据的内存空间大小只能在编译时进行推导。runtime.bmap 中的其他字段在运行时也都是通过计算内存地址的方式访问的，所以它的定义中就不包含这些字段，不过我们能根据编译期间的 cmd/compile/internal/gc.bmap 函数重建它的结构：\n1 2 3 4 5 6 7  type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr }   随着哈希表存储的数据逐渐增多，我们会扩容哈希表或者使用额外的桶存储溢出的数据，不会让单个桶中的数据超过 8 个，不过溢出桶只是临时的解决方案，创建过多的溢出桶最终也会导致哈希的扩容。\n读写操作 访问 1 2  v := hash[key] // =\u0026gt; v := *mapaccess1(maptype, hash, \u0026amp;key) v, ok := hash[key] // =\u0026gt; v, ok := mapaccess2(maptype, hash, \u0026amp;key)   赋值语句左侧接受参数的个数会决定使用的运行时方法：\n 当接受一个参数时，会使用 runtime.mapaccess1，该函数仅会返回一个指向目标值的指针 当接受两个参数时，会使用 runtime.mapaccess2，除了返回目标值之外，它还会返回一个用于表示当前键对应的值是否存在的 bool 值  runtime.mapaccess1 会先通过哈希表设置的哈希函数、种子获取当前键对应的哈希，再通过 runtime.bucketMask 和 runtime.add 拿到该键值对所在的桶序号和哈希高位的 8 位数字。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  func mapaccess1(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) m := bucketMask(h.B) b := (*bmap)(add(h.buckets, (hash\u0026amp;m)*uintptr(t.bucketsize))) top := tophash(hash) bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v } } } return unsafe.Pointer(\u0026amp;zeroVal[0]) }   在 bucketloop 循环中，哈希会依次遍历正常桶和溢出桶中的数据，它会先比较哈希的高 8 位和桶中存储的 tophash是否一致，后比较传入的key和桶中的值以加速数据的读写。用于选择桶序号的是哈希的最低B位，而用于加速访问的是哈希的高 8 位，这种设计能够减少同一个桶中有大量相等 tophash 的概率影响性能。\n如上图所示，每一个桶都是一整片的内存空间，当发现桶中的 tophash 与传入键的 tophash 匹配之后，我们会通过指针和偏移量获取哈希中存储的键 keys[0] 并与 key 比较，如果两者相同就会获取目标值的指针 values[0] 并返回。\n另一个同样用于访问哈希表中数据的 runtime.mapaccess2 只是在 runtime.mapaccess1 的基础上多返回了一个标识键值对是否存在的 bool 值：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  func mapaccess2(t *maptype, h *hmap, key unsafe.Pointer) (unsafe.Pointer, bool) { ... bucketloop: for ; b != nil; b = b.overflow(t) { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if alg.equal(key, k) { v := add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) return v, true } } } return unsafe.Pointer(\u0026amp;zeroVal[0]), false }   写入 当形如 hash[k] 的表达式出现在赋值符号左侧时，该表达式也会在编译期间转换成 runtime.mapassign 函数的调用，该函数与 runtime.mapaccess1 比较相似，我们将其分成几个部分依次分析，首先是函数会根据传入的键拿到对应的哈希和桶：\n1 2 3 4 5 6 7 8 9 10  func mapassign(t *maptype, h *hmap, key unsafe.Pointer) unsafe.Pointer { alg := t.key.alg hash := alg.hash(key, uintptr(h.hash0)) h.flags ^= hashWriting again: bucket := hash \u0026amp; bucketMask(h.B) b := (*bmap)(unsafe.Pointer(uintptr(h.buckets) + bucket*uintptr(t.bucketsize))) top := tophash(hash)   然后通过遍历比较桶中存储的 tophash 和键的哈希，如果找到了相同结果就会返回目标位置的地址。其中 inserti 表示目标元素的在桶中的索引，insertk 和 val 分别表示键值对的地址，获得目标地址之后会通过算术计算寻址获得键值对 k 和 val：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  var inserti *uint8 var insertk unsafe.Pointer var val unsafe.Pointer bucketloop: for { for i := uintptr(0); i \u0026lt; bucketCnt; i++ { if b.tophash[i] != top { if isEmpty(b.tophash[i]) \u0026amp;\u0026amp; inserti == nil { inserti = \u0026amp;b.tophash[i] insertk = add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) } if b.tophash[i] == emptyRest { break bucketloop } continue } k := add(unsafe.Pointer(b), dataOffset+i*uintptr(t.keysize)) if !alg.equal(key, k) { continue } val = add(unsafe.Pointer(b), dataOffset+bucketCnt*uintptr(t.keysize)+i*uintptr(t.valuesize)) goto done } ovf := b.overflow(t) if ovf == nil { break } b = ovf }   上述的 for 循环会依次遍历正常桶和溢出桶中存储的数据，整个过程会分别判断 tophash 是否相等、key 是否相等，遍历结束后会从循环中跳出。\n如果当前桶已经满了，哈希会调用 runtime.hmap.newoverflow 创建新桶或者使用 runtime.hmap 预先在 noverflow 中创建好的桶来保存数据，新创建的桶不仅会被追加到已有桶的末尾，还会增加哈希表的 noverflow 计数器。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  if inserti == nil { newb := h.newoverflow(t, b) inserti = \u0026amp;newb.tophash[0] insertk = add(unsafe.Pointer(newb), dataOffset) val = add(insertk, bucketCnt*uintptr(t.keysize)) } typedmemmove(t.key, insertk, key) *inserti = top h.count++ done: return val }   如果当前键值对在哈希中不存在，哈希会为新键值对规划存储的内存地址，通过 runtime.typedmemmove 将键移动到对应的内存空间中并返回键对应值的地址 val。如果当前键值对在哈希中存在，那么就会直接返回目标区域的内存地址，哈希并不会在 runtime.mapassign 这个运行时函数中将值拷贝到桶中，该函数只会返回内存地址，真正的赋值操作是在编译期间插入的：\n1 2 3 4  00018 (+5) CALL runtime.mapassign_fast64(SB) 00020 (5) MOVQ 24(SP), DI ;; DI = \u0026amp;value 00026 (5) LEAQ go.string.\u0026#34;88\u0026#34;(SB), AX ;; AX = \u0026amp;\u0026#34;88\u0026#34; 00027 (5) MOVQ AX, (DI) ;; *DI = AX   runtime.mapassign_fast64 与 runtime.mapassign 函数的逻辑差不多，我们需要关注的是后面的三行代码，其中 24(SP) 是该函数返回的值地址，我们通过 LEAQ 指令将字符串的地址存储到寄存器 AX 中，MOVQ 指令将字符串 \u0026ldquo;88\u0026rdquo; 存储到了目标地址上完成了这次哈希的写入。\n扩容 以下两种情况会触发map的扩容操作：\n 装载因子超过阈值，源码里定义的阈值是 6.5 overflow 的 bucket 数量过多：当 B 小于 15，也就是 bucket 总数 2^B 小于 2^15 时，如果 overflow 的 bucket 数量超过 2^B；当 B \u0026gt;= 15，也就是 bucket 总数 2^B 大于等于 2^15，如果 overflow 的 bucket 数量超过 2^15  Go源码定义装载因子：loadFactor = count / (2^B)。count就是元素map的个数，2^B表示bucket的数量。对应的扩容源码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // src/runtime/hashmap.go/mapassign  // 触发扩容时机 if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(int64(h.count), h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) } // 装载因子超过 6.5 func overLoadFactor(count int64, B uint8) bool { return count \u0026gt;= bucketCnt \u0026amp;\u0026amp; float32(count) \u0026gt;= loadFactor*float32((uint64(1)\u0026lt;\u0026lt;B)) } // overflow buckets 太多 func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { if B \u0026lt; 16 { return noverflow \u0026gt;= uint16(1)\u0026lt;\u0026lt;B } return noverflow \u0026gt;= 1\u0026lt;\u0026lt;15 }   对于命中条件 1，2 的限制，都会发生扩容。但是扩容的策略并不相同，毕竟两种条件应对的场景不同。\n对于条件 1，元素太多，而 bucket 数量太少，很简单：将 B 加 1，bucket 最大数量（2^B）直接变成原来 bucket 数量的 2 倍。于是，就有新老 bucket 了。注意，这时候元素都在老 bucket 里，还没迁移到新的 bucket 来。而且，新 bucket 只是最大数量变为原来最大数量（2^B）的 2 倍（2^B * 2）。\n对于条件 2，其实元素没那么多，但是 overflow bucket 数特别多，说明很多 bucket 都没装满。解决办法就是开辟一个新 bucket 空间，将老 bucket 中的元素移动到新 bucket，使得同一个 bucket 中的 key 排列地更紧密。这样，原来，在 overflow bucket 中的 key 可以移动到 bucket 中来。结果是节省空间，提高 bucket 利用率，map 的查找和插入效率自然就会提升。\n对于条件 2 的解决方案，还可能一个极端的情况：如果插入 map 的 key 哈希都一样，就会落到同一个 bucket 里，超过 8 个就会产生 overflow bucket，结果也会造成 overflow bucket 数过多。移动元素其实解决不了问题，因为这时整个哈希表已经退化成了一个链表，操作效率变成了 O(n)。\n由于 map 扩容需要将原有的 key/value 重新搬迁到新的内存地址，如果有大量的 key/value 需要搬迁，会非常影响性能。因此 Go map 的扩容采取了一种称为“渐进式”地方式，原有的 key 并不会一次性搬迁完毕，每次最多只会搬迁 2 个 bucket。\n扩容的入口是runtime.hashGrow()函数的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  func hashGrow(t *maptype, h *hmap) { // B+1 相当于是原来 2 倍的空间 \tbigger := uint8(1) // 对应触发条件 2 \tif !overLoadFactor(int64(h.count), h.B) { // 进行等量的内存扩容，所以 B 不变 \tbigger = 0 h.flags |= sameSizeGrow } // 将老 buckets 挂到 buckets 上 \toldbuckets := h.buckets // 申请新的 buckets 空间 \tnewbuckets, nextOverflow := makeBucketArray(t, h.B+bigger) flags := h.flags \u0026amp;^ (iterator | oldIterator) if h.flags\u0026amp;iterator != 0 { flags |= oldIterator } // 提交 grow 的动作 \th.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets // 搬迁进度为 0 \th.nevacuate = 0 // overflow buckets 数为 0 \th.noverflow = 0 // …… }   可以看出hashGrow()函数并没有真正的迁移bucket，而只是分配好了新的 buckets，并将老的 buckets 挂到了 oldbuckets 字段上。\n真正搬迁 buckets 的动作在 growWork() 函数中，而调用 growWork() 函数的动作是在 mapassign 和 mapdelete 函数中。也就是插入或修改、删除 key 的时候，都会尝试进行搬迁 buckets 的工作。先检查 oldbuckets 是否搬迁完毕，具体来说就是检查 oldbuckets 是否为 nil。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  func growWork(t *maptype, h *hmap, bucket uintptr) { // 确认搬迁老的 bucket 对应正在使用的 bucket \tevacuate(t, h, bucket\u0026amp;h.oldbucketmask()) // 再搬迁一个 bucket，以加快搬迁进程 \tif h.growing() { evacuate(t, h, h.nevacuate) } } func (h *hmap) growing() bool { // 如果oldbuckets不为nil，说明需要搬迁 \treturn h.oldbuckets != nil }   bucket\u0026amp;h.oldbucketmask() 这行代码，如源码注释里说的，是为了确认搬迁的 bucket 是我们正在使用的 bucket。oldbucketmask() 函数返回扩容前的 map 的 bucketmask。bucketmask的作用就是与用key计算出来的哈希值相与，得到的结果就是key应该落入的bucket。比如B=5，那么 bucketmask 的低五位就是 11111 ,其余位就是0，hash 值与其相与的意思是，只有 hash 值的低 5 位决策 key 到底落入哪个 bucket。\n接下来是搬迁的关键函数 evacuate()的源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186  func evacuate(t *maptype, h *hmap, oldbucket uintptr) { // 定位老的 bucket 地址 \tb := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) // 结果是 2^B，如 B = 5，结果为32 \tnewbit := h.noldbuckets() // key 的哈希函数 \talg := t.key.alg // 如果 b 没有被搬迁过 \tif !evacuated(b) { var ( // 表示bucket 移动的目标地址 \tx, y *bmap // 指向 x,y 中的 key/val \txi, yi int // 指向 x，y 中的 key \txk, yk unsafe.Pointer // 指向 x，y 中的 value \txv, yv unsafe.Pointer ) // 默认是等 size 扩容，前后 bucket 序号不变 \t// 使用 x 来进行搬迁 \tx = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) xi = 0 xk = add(unsafe.Pointer(x), dataOffset) xv = add(xk, bucketCnt*uintptr(t.keysize))、 // 如果不是等 size 扩容，前后 bucket 序号有变 \t// 使用 y 来进行搬迁 \tif !h.sameSizeGrow() { // y 代表的 bucket 序号增加了 2^B \ty = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) yi = 0 yk = add(unsafe.Pointer(y), dataOffset) yv = add(yk, bucketCnt*uintptr(t.keysize)) } // 遍历所有的 bucket，包括 overflow buckets \t// b 是老的 bucket 地址 \tfor ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) v := add(k, bucketCnt*uintptr(t.keysize)) // 遍历 bucket 中的所有 cell \tfor i := 0; i \u0026lt; bucketCnt; i, k, v = i+1, add(k, uintptr(t.keysize)), add(v, uintptr(t.valuesize)) { // 当前 cell 的 top hash 值 \ttop := b.tophash[i] // 如果 cell 为空，即没有 key \tif top == empty { // 那就标志它被\u0026#34;搬迁\u0026#34;过 \tb.tophash[i] = evacuatedEmpty // 继续下个 cell \tcontinue } // 正常不会出现这种情况 \t// 未被搬迁的 cell 只可能是 empty 或是 \t// 正常的 top hash（大于 minTopHash） \tif top \u0026lt; minTopHash { throw(\u0026#34;bad map state\u0026#34;) } k2 := k // 如果 key 是指针，则解引用 \tif t.indirectkey { k2 = *((*unsafe.Pointer)(k2)) } // 默认使用 X，等量扩容 \tuseX := true // 如果不是等量扩容 \tif !h.sameSizeGrow() { // 计算 hash 值，和 key 第一次写入时一样 \thash := alg.hash(k2, uintptr(h.hash0)) // 如果有协程正在遍历 map \tif h.flags\u0026amp;iterator != 0 { // 如果出现 相同的 key 值，算出来的 hash 值不同 \tif !t.reflexivekey \u0026amp;\u0026amp; !alg.equal(k2, k2) { // 只有在 float 变量的 NaN() 情况下会出现 \tif top\u0026amp;1 != 0 { // 第 B 位置 1 \thash |= newbit } else { // 第 B 位置 0 \thash \u0026amp;^= newbit } // 取高 8 位作为 top hash 值 \ttop = uint8(hash \u0026gt;\u0026gt; (sys.PtrSize*8 - 8)) if top \u0026lt; minTopHash { top += minTopHash } } } // 取决于新哈希值的 oldB+1 位是 0 还是 1 \tuseX = hash\u0026amp;newbit == 0 } // 如果 key 搬到 X 部分 \tif useX { // 标志老的 cell 的 top hash 值，表示搬移到 X 部分 \tb.tophash[i] = evacuatedX // 如果 xi 等于 8，说明要溢出了 \tif xi == bucketCnt { // 新建一个 bucket \tnewx := h.newoverflow(t, x) x = newx // xi 从 0 开始计数 \txi = 0 // xk 表示 key 要移动到的位置 \txk = add(unsafe.Pointer(x), dataOffset) // xv 表示 value 要移动到的位置 \txv = add(xk, bucketCnt*uintptr(t.keysize)) } // 设置 top hash 值 \tx.tophash[xi] = top // key 是指针 \tif t.indirectkey { // 将原 key（是指针）复制到新位置 \t*(*unsafe.Pointer)(xk) = k2 // copy pointer \t} else { // 将原 key（是值）复制到新位置 \ttypedmemmove(t.key, xk, k) // copy value \t} // value 是指针，操作同 key \tif t.indirectvalue { *(*unsafe.Pointer)(xv) = *(*unsafe.Pointer)(v) } else { typedmemmove(t.elem, xv, v) } // 定位到下一个 cell \txi++ xk = add(xk, uintptr(t.keysize)) xv = add(xv, uintptr(t.valuesize)) } else { // key 搬到 Y 部分，操作同 X 部分 \t// …… \t// 省略了这部分，操作和 X 部分相同 \t} } } // 如果没有协程在使用老的 buckets，就把老 buckets 清除掉，帮助gc \tif h.flags\u0026amp;oldIterator == 0 { b = (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) // 只清除bucket 的 key,value 部分，保留 top hash 部分，指示搬迁状态 \tif t.bucket.kind\u0026amp;kindNoPointers == 0 { memclrHasPointers(add(unsafe.Pointer(b), dataOffset), uintptr(t.bucketsize)-dataOffset) } else { memclrNoHeapPointers(add(unsafe.Pointer(b), dataOffset), uintptr(t.bucketsize)-dataOffset) } } } // 更新搬迁进度 \t// 如果此次搬迁的 bucket 等于当前进度 \tif oldbucket == h.nevacuate { // 进度加 1 \th.nevacuate = oldbucket + 1 // Experiments suggest that 1024 is overkill by at least an order of magnitude. \t// Put it in there as a safeguard anyway, to ensure O(1) behavior. \t// 尝试往后看 1024 个 bucket \tstop := h.nevacuate + 1024 if stop \u0026gt; newbit { stop = newbit } // 寻找没有搬迁的 bucket \tfor h.nevacuate != stop \u0026amp;\u0026amp; bucketEvacuated(t, h, h.nevacuate) { h.nevacuate++ } // 现在 h.nevacuate 之前的 bucket 都被搬迁完毕 \t// 所有的 buckets 搬迁完毕 \tif h.nevacuate == newbit { // 清除老的 buckets \th.oldbuckets = nil // 清除老的 overflow bucket \t// 回忆一下：[0] 表示当前 overflow bucket \t// [1] 表示 old overflow bucket \tif h.extra != nil { h.extra.overflow[1] = nil } // 清除正在扩容的标志位 \th.flags \u0026amp;^= sameSizeGrow } } }   搬迁的目的是将老桶内的数据迁移到新桶内。对于条件1翻倍扩容，新桶的数量是老桶的两倍；对于条件2等量扩容，新桶的数量与之前相等。\n对于等量扩容，因为桶的数量不变，所以可以按序号进行搬迁。比如原来是0号桶的，在扩容迁移之后，还是存放在0号桶内。\n对于翻倍扩容，则需要重写计算key的哈希值，来决定将要落入哪个桶中。例如，原来 B = 5，计算出 key 的哈希后，只用看它的低 5 位，就能决定它落在哪个 bucket。扩容后，B 变成了 6，因此需要多看一位，它的低 6 位决定 key 落在哪个 bucket。这称为 rehash。\n因此，key在搬迁前后bucket序号可能与原来一致，也可能是原来的序号加上2^B（原来的B值）,取决于 hash 值 第 6 bit 位是 0 还是 1。\n再明确一个问题：如果扩容后，B 增加了 1，意味着 buckets 总数是原来的 2 倍，原来 1 号的桶“裂变”到两个桶。\n例如，原始 B = 2，1号 bucket 中有 2 个 key 的哈希值低 3 位分别为：010，110。由于原来 B = 2，所以低 2 位 10 决定它们落在 2 号桶，现在 B 变成 3，所以 010、110 分别落入 2、6 号桶。\nevacuate() 函数每次只完成一个 bucket 的搬迁工作，因此要遍历完此 bucket 的所有的 cell，将有值的 cell copy 到新的地方。bucket 还会链接 overflow bucket，它们同样需要搬迁。因此会有 2 层循环，外层遍历 bucket 和 overflow bucket，内层遍历 bucket 的所有 cell。\n源码里提到 X, Y part，其实就是我们说的如果是扩容到原来的 2 倍，桶的数量是原来的 2 倍，前一半桶被称为 X part，后一半桶被称为 Y part。一个 bucket 中的 key 可能会分裂落到 2 个桶，一个位于 X part，一个位于 Y part。所以在搬迁一个 cell 之前，需要知道这个 cell 中的 key 是落到哪个 Part。很简单，重新计算 cell 中 key 的 hash，并向前“多看”一位，决定落入哪个 Part，这个前面也说得很详细了。\n确定了要搬迁到的目标 bucket 后，搬迁操作就比较好进行了。将源 key/value 值 copy 到目的地相应的位置。\n设置 key 在原始 buckets 的 tophash 为 evacuatedX 或是 evacuatedY，表示已经搬迁到了新 map 的 x part 或是 y part。新 map 的 tophash 则正常取 key 哈希值的高 8 位。\n下面通过图来宏观地看一下扩容前后的变化。\n扩容前，B = 2，共有 4 个 buckets，lowbits 表示 hash 值的低位。假设我们不关注其他 buckets 情况，专注在 2 号 bucket。并且假设 overflow 太多，触发了等量扩容（对应于前面的条件 2）。\n扩容完成后，overflow bucket 消失了，key 都集中到了一个 bucket，更为紧凑了，提高了查找的效率。\n假设触发了 2 倍的扩容，那么扩容完成后，老 buckets 中的 key 分裂到了 2 个 新的 bucket。一个在 x part，一个在 y 的 part。依据是 hash 的 lowbits。新 map 中 0-3 称为 x part，4-7 称为 y part。\n无论哪种扩容，扩容操作都不是一个原子操作，而是渐进式的扩容，会在map的插入、修改、删除操作是尝试搬迁桶的工作，也就是执行 growWork()函数。\n删除 想要删除map中的元素，需要使用关键字 delete。这个关键字的唯一作用就是将某一个键对应的元素从哈希表中删除，无论是该键对应的值是否存在，这个内建的函数都不会返回任何的结果。\n删除操作首先会检查 h.flag 标志，如果发现写标位是 1，直接 panic，因为这表明有其他协程同时在进行写操作。然后计算 key 的哈希，找到落入的 bucket。检查此 map 如果正在扩容的过程中，直接触发一次搬迁操作。\n","date":"2023-12-20T16:43:23+08:00","permalink":"https://example.com/p/golang-notes%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Golang Notes：数据类型"}]